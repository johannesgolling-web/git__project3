{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ae278",
   "metadata": {},
   "source": [
    "This notebook builds a simple custom chatbot powered by OpenAI.  \n",
    "It uses the CSV dataset of **2023 fashion trends** and implements a lightweight RAG (retrieve-and-generate) flow without further use of external frameworks.\n",
    "\n",
    "**What you can find**\n",
    "- Load and prepare a dataset (into `text` column)\n",
    "- Create basic retrieval with TF-IDF + cosine similarity\n",
    "- Compare answers **with** vs. **without** custom context\n",
    "- a small interactive loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "For this project, I use the 2023 Fashion Trends dataset 2023_fashion_trends.\n",
    "It contains short text snippets from online articles that describe fashion trends and key style directions in 2023.\n",
    "This dataset should be a good choice because the texts are concise, descriptive, and focus on one single topic â€” fashion.\n",
    "It allows the chatbot to give more specific answers about 2023 trends, such as colors, materials, or design influences.\n",
    "A general OpenAI model could talk about fashion in general, but by adding this dataset, the chatbot becomes more focused and accurate when answering questions about acutal trends in 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931acd52",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Similarity search\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Vocareum API base \n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"YOUR API KEY\" # SET API KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['URL', 'Trends', 'Source']\n",
      "Number of rows: 82\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\P319970\\git_delivery\\git__project3\\data\\raw\\2023_fashion_trends.csv\")\n",
    "\n",
    "# Check existing columns\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Number of rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (82, 3)\n",
      "\n",
      "Missing values per column:\n",
      "URL       0\n",
      "Trends    0\n",
      "Source    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate text rows: 0\n",
      "\n",
      "Average text length: 434.1\n",
      "Minimum text length: 150\n",
      "\n",
      "short entries (< 200 characters):\n",
      "69    \"Leather jackets are leading the nouveau grung...\n",
      "Name: Trends, dtype: object\n",
      "\n",
      "Remaining rows after cleaning: 82\n"
     ]
    }
   ],
   "source": [
    "# data quality check on df\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated(subset=[\"Trends\"]).sum()\n",
    "print(f\"\\nNumber of duplicate text rows: {duplicates}\")\n",
    "\n",
    "# Check average and min length of the trend texts\n",
    "df[\"text_length\"] = df[\"Trends\"].astype(str).apply(len)\n",
    "print(\"\\nAverage text length:\", round(df[\"text_length\"].mean(), 1))\n",
    "print(\"Minimum text length:\", df[\"text_length\"].min())\n",
    "\n",
    "# Show very short or empty entries\n",
    "print(\"\\nshort entries (< 200 characters):\")\n",
    "print(df[df[\"text_length\"] < 200][\"Trends\"].head())\n",
    "\n",
    "# Optional: remove bad rows\n",
    "df = df.dropna(subset=[\"Trends\"])\n",
    "df = df.drop_duplicates(subset=[\"Trends\"])\n",
    "df = df[df[\"text_length\"] > 30].copy()\n",
    "\n",
    "# Check new size\n",
    "print(\"\\nRemaining rows after cleaning:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023 Fashion Trend: Red. Glossy red hues took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023 Fashion Trend: Cargo Pants. Utilitarian w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023 Fashion Trend: Sheer Clothing. \"Bare it a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023 Fashion Trend: Denim Reimagined. From dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023 Fashion Trend: Shine For The Daytime. The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  2023 Fashion Trend: Red. Glossy red hues took ...\n",
       "1  2023 Fashion Trend: Cargo Pants. Utilitarian w...\n",
       "2  2023 Fashion Trend: Sheer Clothing. \"Bare it a...\n",
       "3  2023 Fashion Trend: Denim Reimagined. From dou...\n",
       "4  2023 Fashion Trend: Shine For The Daytime. The..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'text' column out of the column 'Trends', which contains main text content\n",
    "df[\"text\"] = df[\"Trends\"].astype(str).str.strip()\n",
    "\n",
    "# Keep only 'text' column for chatbot context\n",
    "fashion_df = df[[\"text\"]].copy()\n",
    "\n",
    "# Preview first 5 rows\n",
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca355b",
   "metadata": {},
   "source": [
    "### RAG pipeline:\n",
    "- TF-IDF to retrieve most relevant trend snippets\n",
    "- Build custom prompt that injects retrieved context\n",
    "- Call OpenAI Completion model (while keeping basic (no-context) function for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vector index for retrieval\n",
    "assert \"fashion_df\" in globals()\n",
    "assert \"text\" in fashion_df.columns\n",
    "\n",
    "# TF-IDF vectorizer (unigrams + bigrams for better recall when text is short)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1, stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(fashion_df[\"text\"].tolist())\n",
    "\n",
    "def retrieve(query: str, top_k: int = 5):\n",
    "    \"\"\"Returns indices and scores of top_k most relevant rows\"\"\"\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix).ravel()\n",
    "    top_idx = np.argsort(-sims)[:top_k]\n",
    "    return list(zip(top_idx, sims[top_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt builder for basic\n",
    "def build_basic_prompt(question: str) -> str:\n",
    "    return (\n",
    "        \"You are a kind and very helpful assistant. Answer in clear, simple English.\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "# Prompt builder for custom\n",
    "def build_custom_prompt(question: str, context_chunks: list) -> str:\n",
    "    context_text = \"\\n\\n\".join(f\"- {c}\" for c in context_chunks)\n",
    "    return (\n",
    "        \"You are a professional Fashion Trend Assistant. Use only the provided context to answer.\\n\"\n",
    "        \"Be very concise. If the answer is not in the context, say you don't know the answer to the question.\\n\\n\"\n",
    "        \"Context:\\n\"\n",
    "        f\"{context_text}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Answer:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set openAI model\n",
    "MODEL = \"gpt-3.5-turbo-instruct\"   \n",
    "\n",
    "def ask_basic(question: str, max_tokens: int = 300, temperature: float = 0.2):\n",
    "    prompt = build_basic_prompt(question)\n",
    "    resp = openai.Completion.create(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return resp.choices[0].text.strip()\n",
    "\n",
    "def ask_with_context(question: str, top_k: int = 5, max_tokens: int = 300, temperature: float = 0.2):\n",
    "    hits = retrieve(question, top_k=top_k)\n",
    "    context = [fashion_df.iloc[i][\"text\"] for i, _ in hits]\n",
    "    prompt = build_custom_prompt(question, context)\n",
    "    resp = openai.Completion.create(\n",
    "        model=MODEL,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return resp.choices[0].text.strip(), context, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c403f543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.153] 2023 Fashion Trend: Cargo Pants. Utilitarian wear is in for 2023, which sets the stage for the return of the cargo pant....\n",
      "[0.126] 2023 Fashion Trend: Maxi Skirts. In response to the ultra unpractical mini skirts of 2022, maxi skirts are here to domin...\n",
      "[0.080] 2023 Fashion Trend: Sheer Clothing. \"Bare it all\" has been the motto since the end of the lockdown. In 2023,  naked dres...\n"
     ]
    }
   ],
   "source": [
    "# Smoke test without API call\n",
    "q_test = \"What were the key colors and materials in 2023 fashion?\"\n",
    "hits = retrieve(q_test, top_k=3)\n",
    "for i, score in hits:\n",
    "    print(f\"[{score:.3f}] {fashion_df.iloc[i]['text'][:120]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive loop with API, just type 'exit' to stop. \n",
    "while True:\n",
    "    q = input(\"\\nAsk about 2023 fashion trends (type 'exit' to quit): \")\n",
    "    if q.strip().lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "    try:\n",
    "        ans_custom, ctx, _ = ask_with_context(q, top_k=5)\n",
    "        ans_basic = ask_basic(q)\n",
    "        print(\"\\n--- Custom (with context) ---\")\n",
    "        print(ans_custom)\n",
    "        print(\"\\n--- Basic (no context) ---\")\n",
    "        print(ans_basic)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "Here we can compare the modelâ€™s answers with and without custom context.\n",
    "For each question the questions shows:\n",
    "- Basic: model answer without any dataset context\n",
    "- Custom: model answer using retrieved snippets from the 2023 Fashion Trends dataset\n",
    "- additional: the retrieved context used for the custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Function to compare basic vs custom for a given question\n",
    "\n",
    "def show_comparison(question: str, top_k: int = 5, ctx_preview_chars: int = 180):\n",
    "    print(f\"Q: {question}\\n\")\n",
    "    \n",
    "    # Custom (with context)\n",
    "    custom_answer, context, hits = ask_with_context(question, top_k=top_k)\n",
    "    print(\"=== Custom (with context) ===\")\n",
    "    print(custom_answer.strip(), \"\\n\")\n",
    "    \n",
    "    # Basic (without context)\n",
    "    basic_answer = ask_basic(question)\n",
    "    print(\"=== Basic (no context) ===\")\n",
    "    print(basic_answer.strip(), \"\\n\")\n",
    "    \n",
    "    # Show retrieved context used\n",
    "    print(\"=== Retrieved context (top_k) ===\")\n",
    "    for (i, score), chunk in zip(hits, context):\n",
    "        preview = chunk[:ctx_preview_chars].replace(\"\\n\", \" \")\n",
    "        print(f\"[score={score:.3f}] {preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a226f0",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "What does 'quiet luxury' mean in 2023 fashion, and how was it expressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab392da",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"What does 'quiet luxury' mean in 2023 fashion, and how was it expressed?\"\n",
    "show_comparison(q1, top_k=5, ctx_preview_chars=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Which sustainability themes were highlighted in 2023 fashion trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412748e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"Which sustainability themes were highlighted in 2023 fashion trends?\"\n",
    "show_comparison(q2, top_k=5, ctx_preview_chars=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
